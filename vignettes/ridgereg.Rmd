---
title: "ridgereg"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ridgereg}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(linearRegression)
library(caret)
library(mlbench)
library(leaps)
```

```{r}
label <- "Linear Regression with Forward Selection, including intercept only"
type <- "Regression"
parameters <- data.frame(paramater = "nvmax", class = "numeric", label = "Maximum numbers of Predictors")
grid <- function (x, y, len = NULL, search = "grid") 
{
    if (search == "grid") {
        out <- data.frame(nvmax = 2:(len + 1))
    }
    else {
        out <- data.frame(nvmax = sort(unique(sample(2:(ncol(x) - 
            1), size = len, replace = TRUE))))
    }
    out
}

loop <- function (grid) 
{
    grid <- grid[order(grid$nvmax, decreasing = TRUE), , drop = FALSE]
    loop <- grid[1, , drop = FALSE]
    submodels <- list(grid[-1, , drop = FALSE])
    list(loop = loop, submodels = submodels)
}

fitF <- function (x, y, wts, param, lev, last, classProbs, ...) 
{
    theDots <- list(...)
    if (any(names(theDots) == "nbest")) 
        stop("'nbest' should not be specified")
    if (any(names(theDots) == "method")) 
        stop("'method' should not be specified")
    if (any(names(theDots) == "nvmax")) 
        stop("'nvmax' should not be specified")
    leaps::regsubsets(as.matrix(x), y, weights = if (!is.null(wts)) 
        wts
    else rep(1, length(y)), nbest = 1, nvmax = param$nvmax, method = "forward", 
        ...)
}

predictF <- function (modelFit, newdata, submodels = NULL) 
{
    newdata <- as.matrix(newdata)
    foo <- function(b, x) x[, names(b), drop = FALSE] %*% b
    path <- 1:(modelFit$nvmax - 1)
    betas <- coef(modelFit, id = 1:(modelFit$nvmax - 1))
    newdata <- cbind(rep(1, nrow(newdata)), as.matrix(newdata))
    colnames(newdata)[1] <- "(Intercept)"
    out <- foo(betas[[length(betas)]], newdata)[, 1]
    if (!is.null(submodels)) {
        numTerms <- unlist(lapply(betas, length))
        if (any(names(betas[[length(betas)]]) == "(Intercept)")) 
            numTerms <- numTerms - 1
        keepers <- which(numTerms %in% submodels$nvmax)
        if (length(keepers) != length(submodels$nvmax)) 
            stop("Some values of 'nvmax' are not in the model sequence.")
        keepers <- rev(keepers)
        preds <- lapply(betas[keepers], foo, x = newdata)
        preds <- do.call("cbind", preds)
        out <- as.data.frame(cbind(out, preds), stringsAsFactors = TRUE)
        out <- as.list(out)
    }
    out
}

sortF <- function (x) 
x[order(x[, 1]), ]

leapForward_modified <- list(label = label, type = type, parameters = parameters, 
                             grid = grid, loop = loop, fit = fitF, predict = predictF, sort = sortF, prob = NULL, library = NULL)
```

```{r}
data(BostonHousing)

# Get indeces of rows to include in training set
train_index <- caret::createDataPartition(BostonHousing$medv, p=0.6, list=FALSE, times=1)

# Create train and test data
train_data <- BostonHousing[train_index,]
test_data <- BostonHousing[-train_index,]

lm <- train(medv ~ ., data=train_data, method="lm")
lm_forward <- train(medv ~ ., data=train_data, method=leapForward_modified, trControl = trainControl(search = "grid"),
                    tuneGrid  = data.frame(nvmax = ncol(train_data)-1))

lm_pred <- predict(lm, test_data)
lm_forward_pred <- predict(lm_forward, test_data)

postResample(lm_pred, test_data$medv)
postResample(lm_forward_pred, test_data$medv)

ridgereg(medv ~ ., data=train_data, lambda=0, scale=TRUE)
```
