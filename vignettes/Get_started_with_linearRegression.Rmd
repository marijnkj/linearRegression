---
title: "Get_started_with_linearRegression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get_started_with_linearRegression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

linearPackage introduces a way of solving (multiple) linear regression on either numerical data, categorical data, or a combination of them. The Iris dataset categorical data of three different species of iris flowers, along with numerical data of the width and length of their petals and sepals.

```{r setup}
data("iris")
```

## Using the function

The function could be called directly from the package linearRegression, or from your environment once you attached the package to your active library.

In the example below, we doing a linear regression on the iris data, where Sepal.Length is established as our response variable in the formula argument. " Sepal.Length \~ . " means that the regression is supposed to be done on all other variables in the dataset as explanatory variables.

The regression is made and saved in your environment under whichever name you choose, here as "myModel".

```{r}

myModel <- 
  linearRegression::linreg(formula = Sepal.Length ~ . ,data =  iris)

# alternatively

library(linearRegression)

myModel <- linreg(formula = Sepal.Length ~ . ,data = iris)
```

### Choosing explanatory variables

In the last example, we established the length of the iris sepals (Sepal.Length) as the variable that we want to explain through our regression. We could try to use the width (Sepal.Width) of the sepals as an explanatory variable.

```{r}

myFormula <- Sepal.Length ~ Sepal.Width

linreg(formula = myFormula, data = iris)
```

#### Adding categorical variables

As our last model only explains the **average** iris flowers sepal length through its sepal width, we now also want to take the iris species into account.

Species is therefore a categorical variable, which are stored in data frames wither in factor-class or character-class.

```{r}

class(iris$Species)
levels(iris$Species)

myFormula <- Sepal.Length ~ Sepal.Width + Species


linreg(formula = myFormula, data = iris)

```

#### Transforming variables

In some more advanced cases of multiple regression, we could want to use polynomials or other functions to transform our variables.

In the example below, we will tranform our Sepal.Width variable into a second degree polynomial, as well as adding the natural logarithm of petal length (Petal.Length).

Although this could be done through calculating these transformed variables seperately, and then adding them to our dataset - It could as well be done in the formula directly using the I() function which tells the formula to read the argument as a transformation rather than a variable name.:

```{r}


myFormula <- Sepal.Length ~ Sepal.Width + I(Sepal.Width^2) + I(log(Petal.Width)) + Species


linreg(formula = myFormula, data = iris)

```

#### Adding interaction terms

Lastly, we could also add interaction terms between the variables. If we want to add the width of the petals (Petal.Width), as we suspect there being a significantly different relation between our response variable and the petal width depending on the species. An interaction term could be added alongside the variable. This is done through adding a ":" between the variables of which you suspect interaction.

```{r}


myFormula <- Sepal.Length ~ Sepal.Width + I(Sepal.Width^2) + I(log(Petal.Width)) + Petal.Width + Species + Petal.Width:Species


myModel <- linreg(formula = myFormula, data = iris)

myModel
```

### Evaluating your model

```{r}
summary(myModel)

```

Using the function summary() at our model-object gives us following output: A table is printed containing the beta-coefficient estimates for every explanatory variable supplied in the input formula, along with its standard errors. A t-value for each explanatory variable estimate is included in the output, which is used to calculate the p-value (Pr(\>\|t\|)) for double sided t-test. Often p \< 0.05 indicates statistically significant effect.

#### Residual analysis

```{r}
plot(myModel)

```

Although the majority of residual analysis must be done manually, the function supplies two plots accessed easiest through the print()-function. This provides two graphs where the resduals are plotted after fitted value along the x-axis. A red line is drawn through the median residual of every fitted value, in case one fitted value corresponds with different residuals. The first (upper) plot shows the residuals (how much the fitted values differs from data input) on y-axis. The second (lower) plot shows the square root of the standardized residuals on y-axis.

### Linreg as a class object

```{r}
## linreg$new(formula, data) == linreg(formula, data)

myModel <- linreg$new(formula, data)

class(linreg)
class(myModel)
```

The function which calculates the regression is contained in an object generator which creates and object of class "linreg". In the creation of a new "linreg", the input is used on the function. Not only are the basic results printed at the creation of the object, they are also saved inside the object to be accessed later at command.

#### Methods and fields

```{r}

#beta coefficients
myModel$beta_hats

#10 first residuals, accessed through resid()
head(resid(myModel), 10)



```

##### Methods

-   Print coefficients -\> linreg_mod\$print()

-   Print summary of linear regression -\> linreg_mod\$summary()

-   Plot some basic graphs -\> linreg_mod\$plot()

-   Get residuals -\> linreg_mod\$resid()

-   Get y-hat values -\> linreg_mod\$pred()

-   Get coefficients -\> linreg_mod\$coef()

##### Fields

-   formula = An R formula describing the desired formula for the linear regression

-   data = A data.frame containing the necessary data for the linear regression

-   beta_hat = A matrix with the estimated coefficients

-   y_hat = A matrix with the predicted values for y

-   res = A matrix with the residuals

-   df = Degrees of freedom

-   res_var = Variance of the residuals

-   var_beta_hats = Variance of the estimated coefficients

-   t_beta_hats = A matrix of t-values for the estimated coefficients

-   p_beta_hats = A matrix of p-values for the estimated coefficients (t-test)

-   formula_call = The formula as used in the object initialization

-   data_call = The data as used in the object initialization

### How does it work?

Linreg utilizes ordinary least squares-method to calculate regression coefficients through matrix algebra.

```{r}
                        formula <- formula
                        data <- data
                        formula_call <- deparse(substitute(formula))
                        data_call <- deparse(substitute(data))
                        
                        X <- model.matrix(formula, data) # https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/model.matrix
                        y <- as.matrix(data[all.vars(formula)[1]])
                        
                        beta_hats <- solve(t(X) %*% X) %*% t(X) %*% y
                        y_hat <- X %*% beta_hats
                        res <- y - y_hat
                        df <- length(y) - length(beta_hats)
                        res_var <- ((t(res) %*% res) / df)[1] # [1] to access the value
                        var_beta_hats <- diag(res_var * solve(t(X) %*% X))
                        t_beta_hats <- beta_hats / sqrt(var_beta_hats)
                        p_beta_hats <- pt(abs(t_beta_hats), df, lower.tail=FALSE)*2 # x2 for two-tailed p-values
```

### Custom theme: LiU

```{r}
# Plot the residuals with a theme matching the graphic profile of LinkÃ¶pings University!

myModel$plot(theme = "liu")
```
